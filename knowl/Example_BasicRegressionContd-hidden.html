<!DOCTYPE html>
<html lang="en-US">
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2020-07-03T19:26:27-06:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body><article class="example example-like"><p>We continue from <a class="xref" data-knowl="./knowl/Example_BasicRegression.html" title="Example 1.5.1">Example 1.5.1</a>:</p>
<div class="displaymath">
\begin{align*}
\bar{x}\amp = \frac{1+2+3+4+5}{5}=3\\
\bar{y}\amp = \frac{2+2+4+4+6}{5}=3.6\\
SS_X\amp = (1-3)^2+(2-3)^2+(3-3)^2+(4-3)^2+(5-3)^2=10\\
SS_Y\amp = (2-3.5)^2+(2-3.5)^2+(4-3.5)^2+(4-3.5)^2+(6-3.5)^2=11.25\\
SS_{XY}\amp = (1-3)(2-3.5)+(2-3)(2-3.5)+(3-3)(4-3.5)+\\
\amp \ \  (4-3)(4-3.5)+(5-3)(6-3.5)=10\\
\beta_1\amp = \frac{10}{10}=1\\
\beta_0\amp = 3.6-(1)(3)=0.6
\end{align*}
</div>
<p>So our best fit line is \(y=1x+0.6\text{.}\)</p>
<div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="images/image-37.svg" style="width: 100%; height: auto;" alt=""></div>
<p>Again, notice that none of the points actually fall on this line, but no possible line could have accomplished all of the points falling on it. What we have instead is a line that passes through the points as closely as possible. Define \(e_i\) to be the error in prediction for \(y_i\text{,}\) that is let \(e_i=y_i-(1\cdot x_i+0.6)\text{,}\) then we see that:</p>
<div class="displaymath">
\begin{align*}
e_1\amp = 2-(1+.6)=0.4\\
e_2\amp = 2-(2+.6)=-0.6\\
e_3\amp = 4-(3+.6)=0.4\\
e_4\amp = 4-(4+.6)=-0.6\\
e_5\amp = 6-(5+.6)=0.4
\end{align*}
</div>
<div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="images/image-38.svg" style="width: 100%; height: auto;" alt=""></div>
<p>But</p>
<div class="displaymath">
\begin{equation*}
e_1+e_2+e_3+e_4+e_5=(0.4)+(-0.6)+(0.4)+(0.6)+(0.4)=0\text{.}
\end{equation*}
</div>
<p>This tells us this line passes through the “middle” of the points. Is it the best possible line? Notice that</p>
<div class="displaymath">
\begin{equation*}
\sum e_i^2=(0.4)^2+(-0.6)^2+(0.4)^2+(0.6)^2+(0.4)^2=1.2\text{.}
\end{equation*}
</div>
<p>Is this the best we can do? Again, a formal verification of this is beyond this text, but following this link: \url{https://www.desmos.com/calculator/gruczlkyyf}, you can see that by adjusting the parameters \(m\) and \(b\text{,}\) that the sum of squares being 1.2 is the smallest error sum you can achieve.</p>
<p>To find \(r\) we note that:</p>
<div class="displaymath">
\begin{align*}
r\amp = \frac{n(\sum x_iy_i)-(\sum x_i)(\sum y_i)}{\sqrt{(n\sum x_i^2) - (\sum x_i)^2}\cdot \sqrt{n(\sum y_i^2)-(\sum y_i)^2}}\\
\amp = \frac{5(64)-(15)(18)}{\sqrt{5(55) - (15)^2}\cdot \sqrt{5(76)-(18)^2}}\\
\amp \approx 0.9449\text{.}
\end{align*}
</div>
<p>So we can see that this fit is fairly close, and \(x\) is a good predictor of \(y\text{.}\) Since \(r^2\approx 0.8929\text{,}\) we can say that \(y\)'s value are 89.29% determinable by \(x\)'s values.</p></article></body>
</html>
